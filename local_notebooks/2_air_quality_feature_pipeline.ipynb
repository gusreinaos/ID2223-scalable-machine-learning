{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4447764c-218b-441a-ab97-4df4062960d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Added the following directory to the PYTHONPATH: /Users/oscarreinagustafsson/Desktop/Projects/Master/machine-learning/ID2223-scalable-machine-learning\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path().absolute()\n",
    "# Strip subdirectory if notebook started inside project subfolders\n",
    "if root_dir.parts[-1:] == ('airquality',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "if root_dir.parts[-1:] == ('notebooks',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "if root_dir.parts[-1:] == ('local_notebooks',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "if root_dir.parts[-1:] == ('collab_notebooks',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "root_dir = str(root_dir) \n",
    "print(\"Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    \n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from airquality.config import HopsworksSettings\n",
    "settings = HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Daily Feature Pipeline for Air Quality (aqicn.org) and weather (openmeteo)</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Download and Parse Data\n",
    "2. Feature Group Insertion\n",
    "\n",
    "\n",
    "__This notebook should be scheduled to run daily__\n",
    "\n",
    "In the book, we use a GitHub Action stored here:\n",
    "[.github/workflows/air-quality-daily.yml](https://github.com/featurestorebook/mlfs-book/blob/main/.github/workflows/air-quality-daily.yml)\n",
    "\n",
    "However, you are free to use any Python Orchestration tool to schedule this program to run daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe638c6",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from airquality import util\n",
    "from airquality import config\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6081d1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç Get the Sensor URL, Country, City, Street names from Hopsworks </span>\n",
    "\n",
    "__Update the values in the cell below.__\n",
    "\n",
    "__These should be the same values as in notebook 1 - the feature backfill notebook__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-18 13:43:43,192 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-18 13:43:43,194 INFO: Initializing external client\n",
      "2025-11-18 13:43:43,195 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-18 13:43:45,046 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"country\": \"sweden\", \"city\": \"skelleftea-kv-pantern\", \"street\": \"viktoriagatan\", \"aqicn_url\": \"https://api.waqi.info/feed/@13982/\", \"latitude\": \"64.75\", \"longitude\": \"20.96\"}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() \n",
    "secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "# This line will fail if you have not registered the AQICN_API_KEY as a secret in Hopsworks\n",
    "AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "location = json.loads(location_str)\n",
    "\n",
    "country=location['country']\n",
    "city=location['city']\n",
    "street=location['street']\n",
    "aqicn_url=location['aqicn_url']\n",
    "latitude=location['latitude']\n",
    "longitude=location['longitude']\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "location_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf9289",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ Get references to the Feature Groups </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=2,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b6ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ffa41",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå´ Retrieve Today's Air Quality data (PM2.5) from the AQI API</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f681af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>sweden</td>\n",
       "      <td>skelleftea-kv-pantern</td>\n",
       "      <td>viktoriagatan</td>\n",
       "      <td>2025-11-18</td>\n",
       "      <td>https://api.waqi.info/feed/@13982/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25 country                   city         street       date  \\\n",
       "0   7.0  sweden  skelleftea-kv-pantern  viktoriagatan 2025-11-18   \n",
       "\n",
       "                                  url  \n",
       "0  https://api.waqi.info/feed/@13982/  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "aq_today_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9e24eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   pm25     1 non-null      float32       \n",
      " 1   country  1 non-null      object        \n",
      " 2   city     1 non-null      object        \n",
      " 3   street   1 non-null      object        \n",
      " 4   date     1 non-null      datetime64[ns]\n",
      " 5   url      1 non-null      object        \n",
      "dtypes: datetime64[ns](1), float32(1), object(4)\n",
      "memory usage: 176.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "aq_today_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af845ab6",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Get Weather Forecast data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2ecb3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 64.75¬∞N 21.0¬∞E\n",
      "Elevation 18.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-18</td>\n",
       "      <td>-7.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.491114</td>\n",
       "      <td>324.782318</td>\n",
       "      <td>skelleftea-kv-pantern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-19</td>\n",
       "      <td>-8.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.287822</td>\n",
       "      <td>267.510498</td>\n",
       "      <td>skelleftea-kv-pantern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-20</td>\n",
       "      <td>-10.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.895416</td>\n",
       "      <td>316.847595</td>\n",
       "      <td>skelleftea-kv-pantern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>-9.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.957108</td>\n",
       "      <td>319.398773</td>\n",
       "      <td>skelleftea-kv-pantern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-22</td>\n",
       "      <td>-12.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.636753</td>\n",
       "      <td>315.000092</td>\n",
       "      <td>skelleftea-kv-pantern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-11-23</td>\n",
       "      <td>-13.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.545584</td>\n",
       "      <td>261.869995</td>\n",
       "      <td>skelleftea-kv-pantern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-11-24</td>\n",
       "      <td>-4.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.826088</td>\n",
       "      <td>8.426887</td>\n",
       "      <td>skelleftea-kv-pantern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  temperature_2m_mean  precipitation_sum  wind_speed_10m_max  \\\n",
       "0 2025-11-18                -7.40                0.0            7.491114   \n",
       "1 2025-11-19                -8.80                0.0            8.287822   \n",
       "2 2025-11-20               -10.70                0.0            7.895416   \n",
       "3 2025-11-21                -9.80                0.0            9.957108   \n",
       "4 2025-11-22               -12.85                0.0            7.636753   \n",
       "5 2025-11-23               -13.85                0.0            2.545584   \n",
       "6 2025-11-24                -4.15                0.6            9.826088   \n",
       "\n",
       "   wind_direction_10m_dominant                   city  \n",
       "0                   324.782318  skelleftea-kv-pantern  \n",
       "1                   267.510498  skelleftea-kv-pantern  \n",
       "2                   316.847595  skelleftea-kv-pantern  \n",
       "3                   319.398773  skelleftea-kv-pantern  \n",
       "4                   315.000092  skelleftea-kv-pantern  \n",
       "5                   261.869995  skelleftea-kv-pantern  \n",
       "6                     8.426887  skelleftea-kv-pantern  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "hourly_df = hourly_df.set_index('date')\n",
    "\n",
    "# We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "# We only want the daily weather data, so only get weather at 12:00\n",
    "daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "daily_df = daily_df.reset_index()\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "daily_df['city'] = city\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c563109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         7 non-null      datetime64[ns]\n",
      " 1   temperature_2m_mean          7 non-null      float32       \n",
      " 2   precipitation_sum            7 non-null      float32       \n",
      " 3   wind_speed_10m_max           7 non-null      float32       \n",
      " 4   wind_direction_10m_dominant  7 non-null      float32       \n",
      " 5   city                         7 non-null      object        \n",
      "dtypes: datetime64[ns](1), float32(4), object(1)\n",
      "memory usage: 356.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">‚¨ÜÔ∏è Uploading new data to the Feature Store</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a9de5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.55s) \n",
      "Coordinates 64.75¬∞N 21.0¬∞E\n",
      "Elevation 18.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    }
   ],
   "source": [
    "start_date = today - datetime.timedelta(days=4)\n",
    "\n",
    "last_3_days_aq_query = (\n",
    "    air_quality_fg.select([\"city\", \"pm25\", \"date\"]).filter((air_quality_fg.date >= str(start_date)) & (air_quality_fg.date <= str(today)))\n",
    ")\n",
    "\n",
    "aq_3_days_history_df = last_3_days_aq_query.read()\n",
    "\n",
    "###############\n",
    "# Get today's data\n",
    "aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "\n",
    "for lagged_day in [1,2,3]:\n",
    "    lag_date = today - pd.Timedelta(days=lagged_day)\n",
    "    mask = (aq_3_days_history_df['city'] == city) \\\n",
    "        & (aq_3_days_history_df['date'].dt.date == lag_date)\n",
    "    lag_value = aq_3_days_history_df.loc[mask, 'pm25']\n",
    "    if not lag_value.empty:\n",
    "        aq_today_df[f'lagged_{lagged_day}'] = lag_value.values[0]\n",
    "    else:\n",
    "        aq_today_df[f'lagged_{lagged_day}'] = None\n",
    "\n",
    "hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "hourly_df = hourly_df.set_index('date')\n",
    "\n",
    "# We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "# We only want the daily weather data, so only get weather at 12:00\n",
    "daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "daily_df = daily_df.reset_index()\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "daily_df['city'] = city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d491b0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-18 13:43:53,536 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279132/fs/1265741/fg/1596030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 7/7 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279132/jobs/named/weather_1_offline_fg_materialization/executions\n",
      "2025-11-18 13:44:10,728 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-18 13:44:40,331 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-18 13:46:49,692 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-18 13:46:49,894 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-18 13:47:08,847 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('weather_1_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"precipitation_sum\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 733242\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 0.0,\n",
       "         \"element_count\": 7,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-18T12:43:53.000536Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"wind_speed_10m_max\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 733243\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 2.545584201812744,\n",
       "         \"element_count\": 7,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-18T12:43:53.000536Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 2,\n",
       "     \"successful_expectations\": 2,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"weather_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-11-18T13:43:53.536316+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"3d813420-c47c-11f0-9aab-860770e6205a\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251118T124353.536175Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "weather_fg.insert(daily_df, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9e2d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will read from a feature group and create training dataset within the feature store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ca80f",
   "metadata": {},
   "source": [
    "# WAIT, there's more...\n",
    "\n",
    "## A-grade: make pipeline for all sensors\n",
    "We need to make sure to execute the above cells for each of the sensors that we can find in the Skelleftea area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e932ed3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data folder structure at path: /Users/oscarreinagustafsson/Desktop/Projects/Master/machine-learning/ID2223-scalable-machine-learning/data/extra_sensors\n",
      "Error: Missing files in data directory: ostermalmsgatan-vasterbotten.csv, vittervagen-vasterbotten.csv\n",
      "2025-11-18 13:47:08,869 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-18 13:47:08,873 INFO: Initializing external client\n",
      "2025-11-18 13:47:08,873 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-18 13:47:10,546 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279132\n",
      "Processing file: ac846-skelleftea.csv\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.30s) \n",
      "Coordinates 65.0¬∞N 20.0¬∞E\n",
      "Elevation 202.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "2025-11-18 13:47:17,904 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279132/fs/1265741/fg/1730946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_ac846_skelleftea_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279132/jobs/named/air_quality_ac846_skelleftea_2_offline_fg_materialization/executions\n",
      "2025-11-18 13:47:31,475 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279132/fs/1265741/fg/1719647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 7/7 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_ac846_skelleftea_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279132/jobs/named/weather_ac846_skelleftea_1_offline_fg_materialization/executions\n",
      "2025-11-18 13:47:49,088 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-18 13:47:55,629 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-18 13:49:55,385 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-18 13:49:55,559 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-18 13:50:14,508 INFO: Execution finished successfully.\n",
      "Processing file: mobackavagen-skelleftea.csv\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.05s) \n",
      "Coordinates 64.75¬∞N 21.0¬∞E\n",
      "Elevation 18.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "2025-11-18 13:50:20,150 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279132/fs/1265741/fg/1718843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_mobackavagen_skelleftea_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279132/jobs/named/air_quality_mobackavagen_skelleftea_2_offline_fg_materialization/executions\n",
      "2025-11-18 13:50:34,883 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279132/fs/1265741/fg/1718661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 7/7 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_mobackavagen_skelleftea_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279132/jobs/named/weather_mobackavagen_skelleftea_1_offline_fg_materialization/executions\n",
      "2025-11-18 13:50:52,030 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2025-11-18 13:50:55,314 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-18 13:53:08,061 INFO: Waiting for execution to finish. Current state: SUCCEEDING. Final status: UNDEFINED\n",
      "2025-11-18 13:53:14,531 INFO: Waiting for execution to finish. Current state: FINISHED. Final status: SUCCEEDED\n",
      "2025-11-18 13:53:14,963 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-18 13:53:14,963 INFO: Execution finished successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    extra_sensors = f\"{root_dir}/data/extra_sensors/\"\n",
    "    util.check_data_folder_structure(root_dir)\n",
    "\n",
    "    project = hopsworks.login()\n",
    "    fs = project.get_feature_store() \n",
    "    secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "    import json\n",
    "\n",
    "    try:\n",
    "        with open(f\"{root_dir}/data/extra_sensor_settings.json\", 'r') as file:\n",
    "            settings_json = json.load(file)[\"extra_sensors\"]\n",
    "    except FileNotFoundError:\n",
    "        print(\"Settings file for extra sensors not found.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    for csv_file_name in os.listdir(extra_sensors):\n",
    "        print(f\"Processing file: {csv_file_name}\")\n",
    "        fs = project.get_feature_store() \n",
    "        secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "        # This line will fail if you have not registered the AQICN_API_KEY as a secret in Hopsworks\n",
    "        AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "        location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON_\" + csv_file_name).value\n",
    "        location = json.loads(location_str)\n",
    "\n",
    "        country=location['country']\n",
    "        city=location['city']\n",
    "        street=location['street']\n",
    "        aqicn_url=location['aqicn_url']\n",
    "        latitude=location['latitude']\n",
    "        longitude=location['longitude']\n",
    "\n",
    "        today = datetime.date.today()\n",
    "\n",
    "        import re\n",
    "\n",
    "        ####################\n",
    "        # Retrieve feature groups\n",
    "        # split the .csv extension from the csv_file_name: not compatible with Hopsworks feature group names\n",
    "        csv_file_name_no_ext = os.path.splitext(csv_file_name)[0]\n",
    "        # replace - with _\n",
    "        csv_file_name_no_ext = re.sub(r'[-\\s]', '_', csv_file_name_no_ext)\n",
    "\n",
    "        air_quality_fg = fs.get_feature_group(\n",
    "            name=f'air_quality_{csv_file_name_no_ext}',\n",
    "            version=2,\n",
    "        )\n",
    "        weather_fg = fs.get_feature_group(\n",
    "            name=f'weather_{csv_file_name_no_ext}',\n",
    "            version=1,\n",
    "        )\n",
    "        ###############################\n",
    "        \n",
    "        start_date = today - datetime.timedelta(days=4)\n",
    "\n",
    "        last_3_days_aq_query = (\n",
    "            air_quality_fg.select([\"city\", \"pm25\", \"date\"]).filter((air_quality_fg.date >= str(start_date)) & (air_quality_fg.date <= str(today)))\n",
    "        )\n",
    "\n",
    "        aq_3_days_history_df = last_3_days_aq_query.read()\n",
    "\n",
    "        ###############\n",
    "        # Get today's data\n",
    "        aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "\n",
    "        for lagged_day in [1,2,3]:\n",
    "            lag_date = today - pd.Timedelta(days=lagged_day)\n",
    "            mask = (aq_3_days_history_df['city'] == city) \\\n",
    "                & (aq_3_days_history_df['date'].dt.date == lag_date)\n",
    "            lag_value = aq_3_days_history_df.loc[mask, 'pm25']\n",
    "            if not lag_value.empty:\n",
    "                aq_today_df[f'lagged_{lagged_day}'] = lag_value.values[0]\n",
    "            else:\n",
    "                aq_today_df[f'lagged_{lagged_day}'] = None\n",
    "\n",
    "        hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "        hourly_df = hourly_df.set_index('date')\n",
    "\n",
    "        # We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "        # We only want the daily weather data, so only get weather at 12:00\n",
    "        daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "        daily_df = daily_df.reset_index()\n",
    "        daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "        daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "        daily_df['city'] = city\n",
    "\n",
    "        air_quality_fg.insert(aq_today_df)\n",
    "        weather_fg.insert(daily_df, wait=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ID2223-scalable-machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
